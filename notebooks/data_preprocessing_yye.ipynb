{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPBkhv9S22Z5"
   },
   "source": [
    "## ë°ì´í„° ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXa_jMX2zRtY"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-23T15:09:43.310863Z",
     "iopub.status.busy": "2025-07-23T15:09:43.310630Z",
     "iopub.status.idle": "2025-07-23T15:09:51.020160Z",
     "shell.execute_reply": "2025-07-23T15:09:51.019637Z",
     "shell.execute_reply.started": "2025-07-23T15:09:43.310840Z"
    },
    "id": "xlfm4JdwXpLH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import heapq\n",
    "import torch\n",
    "import json\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from itertools import cycle\n",
    "import random\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.patches as patches\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from google.colab import files\n",
    "import torchvision.transforms.functional as F2\n",
    "from IPython.display import Image as IPImage, display\n",
    "from shutil import copyfile\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-23T15:09:51.021259Z",
     "iopub.status.busy": "2025-07-23T15:09:51.020865Z",
     "iopub.status.idle": "2025-07-23T15:10:16.280004Z",
     "shell.execute_reply": "2025-07-23T15:10:16.279226Z",
     "shell.execute_reply.started": "2025-07-23T15:09:51.021233Z"
    },
    "id": "ZfjZy3TXXpLH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title matplotlib í•œê¸€ ì„¤ì¹˜\n",
    "!sudo apt-get install -y fonts-nanum\n",
    "!sudo fc-cache -fv\n",
    "!rm ~/.cache/matplotlib -rf\n",
    "\n",
    "!apt-get update -qq\n",
    "!apt-get install fonts-nanum* -qq\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
    "plt.rc('font', family=font_name)\n",
    "\n",
    "fm.fontManager.addfont(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEClwt0IuWk3"
   },
   "outputs": [],
   "source": [
    "# @title zip íŒŒì¼ ì••ì¶•í•´ì œ\n",
    "!cp /content/drive/MyDrive/codeit/project/pill_data_v.zip /content/\n",
    "!unzip -q /content/pill_data_v.zip -d /content/ai03-level1-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFEMMqOCsndm"
   },
   "outputs": [],
   "source": [
    "# @title ì‘ì—… ê²½ë¡œ ì§€ì •\n",
    "path = \"/content/ai03-level1-project\"\n",
    "\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T15:11:08.417161Z",
     "iopub.status.busy": "2025-07-23T15:11:08.416984Z",
     "iopub.status.idle": "2025-07-23T15:11:12.360107Z",
     "shell.execute_reply": "2025-07-23T15:11:12.359251Z",
     "shell.execute_reply.started": "2025-07-23T15:11:08.417146Z"
    },
    "id": "TEWDgQOWXpLJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title ë””ë ‰í„°ë¦¬ ê²½ë¡œì§€ì • ë° ìƒì„±\n",
    "root_dir = \"/content/ai03-level1-project\"\n",
    "source_img_dir = \"/content/ai03-level1-project/train_images\"\n",
    "source_label_dir = \"/content/ai03-level1-project/train_annotations\"\n",
    "test_img_dir = \"/content/ai03-level1-project/test_images\"\n",
    "merged_json_dir = \"/content/ai03-level1-project/merge_ann\"\n",
    "yolo_label_dir = \"/content/ai03-level1-project/labels\"\n",
    "yolo_image_dir = \"/content/ai03-level1-project/images\"\n",
    "yolo_train_img_dir = \"/content/ai03-level1-project/images/train_images\"\n",
    "yolo_val_img_dir = \"/content/ai03-level1-project/images/val_images\"\n",
    "yolo_train_label_dir = \"/content/ai03-level1-project/labels/train_images\"\n",
    "yolo_val_label_dir = \"/content/ai03-level1-project/labels/val_images\"\n",
    "yaml_path = \"/content/ai03-level1-project/data.yaml\"\n",
    "merged_json_path = os.path.join(merged_json_dir, \"merged_annotations.json\")\n",
    "merged_filtered_json_path = os.path.join(merged_json_dir, \"merged_filtered_annotations.json\")\n",
    "\n",
    "os.makedirs(merged_json_dir, exist_ok=True)\n",
    "os.makedirs(yolo_label_dir, exist_ok=True)\n",
    "os.makedirs(yolo_image_dir, exist_ok=True)\n",
    "os.makedirs(merged_json_dir, exist_ok=True)\n",
    "os.makedirs(yolo_train_img_dir, exist_ok=True)\n",
    "os.makedirs(yolo_val_img_dir, exist_ok=True)\n",
    "os.makedirs(yolo_train_label_dir, exist_ok=True)\n",
    "os.makedirs(yolo_val_label_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xlGcXe_ssQY"
   },
   "outputs": [],
   "source": [
    "# @title ëª¨ë¸ ì €ì¥ê²½ë¡œ ì§€ì •\n",
    "drive_path = \"/content/drive/MyDrive/codeit/project/model/transtest\"\n",
    "project_name = \"tran_test\"\n",
    "project_path = os.path.join(drive_path, project_name)\n",
    "# os.makedirs(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdJCewW96PHw"
   },
   "source": [
    "## í•„ìš” ë©”ì„œë“œ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-23T15:11:12.361431Z",
     "iopub.status.busy": "2025-07-23T15:11:12.361068Z",
     "iopub.status.idle": "2025-07-23T15:11:12.379200Z",
     "shell.execute_reply": "2025-07-23T15:11:12.378551Z",
     "shell.execute_reply.started": "2025-07-23T15:11:12.361403Z"
    },
    "id": "oHFcmKlnXpLJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title ì–´ë…¸í…Œì´ì…˜ ë³‘í•©\n",
    "def merge_coco_jsons(root_json_dir, merged_json_path):\n",
    "    \"\"\"\n",
    "    COCO í˜•ì‹ì˜ JSON ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ë“¤ì„ ë³‘í•©í•˜ì—¬ í•˜ë‚˜ì˜ JSONìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        root_json_dir (str): JSON íŒŒì¼ë“¤ì´ ìœ„ì¹˜í•œ ìµœìƒìœ„ ë””ë ‰í† ë¦¬ ê²½ë¡œ. í•˜ìœ„ ë””ë ‰í† ë¦¬ê¹Œì§€ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤.\n",
    "        merged_json_path (str): ë³‘í•©ëœ JSON íŒŒì¼ì„ ì €ì¥í•  ê²½ë¡œ.\n",
    "\n",
    "    Returns:\n",
    "        None. ë³‘í•©ëœ ê²°ê³¼ëŠ” merged_json_pathì— ì €ì¥ë©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(merged_json_path), exist_ok=True)\n",
    "\n",
    "    json_files = glob.glob(os.path.join(root_json_dir, '**', '*.json'), recursive=True)\n",
    "    print(f\"[DEBUG] ì°¾ì€ JSON íŒŒì¼ ê°œìˆ˜: {len(json_files)}\")\n",
    "    print(f\"[DEBUG] ì˜ˆì‹œ JSON íŒŒì¼ë“¤: {json_files[:5]}\")\n",
    "\n",
    "    merged = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "    annotation_id = 1\n",
    "    image_id_set = set()\n",
    "    category_set = set()\n",
    "\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        for img in data.get(\"images\", []):\n",
    "            if img[\"id\"] not in image_id_set:\n",
    "                merged[\"images\"].append(img)\n",
    "                image_id_set.add(img[\"id\"])\n",
    "\n",
    "        for ann in data.get(\"annotations\", []):\n",
    "            ann[\"id\"] = annotation_id\n",
    "            annotation_id += 1\n",
    "            merged[\"annotations\"].append(ann)\n",
    "\n",
    "        for cat in data.get(\"categories\", []):\n",
    "            if cat[\"id\"] not in category_set:\n",
    "                merged[\"categories\"].append(cat)\n",
    "                category_set.add(cat[\"id\"])\n",
    "\n",
    "    with open(merged_json_path, 'w') as f:\n",
    "        json.dump(merged, f, indent=2)\n",
    "\n",
    "    print(f\"[DEBUG] ë³‘í•©ëœ JSON ì €ì¥ ì™„ë£Œ: {merged_json_path}\")\n",
    "\n",
    "# ì–´ë…¸í…Œì´ì…˜ ë³‘í•©\n",
    "merge_coco_jsons(source_label_dir, merged_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-23T15:11:12.396781Z",
     "iopub.status.busy": "2025-07-23T15:11:12.396427Z",
     "iopub.status.idle": "2025-07-23T15:11:12.410262Z",
     "shell.execute_reply": "2025-07-23T15:11:12.409615Z",
     "shell.execute_reply.started": "2025-07-23T15:11:12.396765Z"
    },
    "id": "86J906tkXpLJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title ì´ë¯¸ì§€íŒŒì¼ yolo ì´ë¯¸ì§€ ë””ë ‰í„°ë¦¬ë¡œ ë³µì‚¬\n",
    "def copy_images(file_names, source_img_dir, target_img_dir):\n",
    "    \"\"\"\n",
    "    ì§€ì •ëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì›ë³¸ ë””ë ‰í† ë¦¬ì—ì„œ ëŒ€ìƒ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        file_names (list): ë³µì‚¬í•  ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ ë¦¬ìŠ¤íŠ¸.\n",
    "        source_img_dir (str): ì›ë³¸ ì´ë¯¸ì§€ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "        target_img_dir (str): ì´ë¯¸ì§€ë“¤ì„ ë³µì‚¬í•  ëŒ€ìƒ ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "\n",
    "    Returns:\n",
    "        None. íŒŒì¼ì´ target_img_dirë¡œ ë³µì‚¬ë©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    os.makedirs(target_img_dir, exist_ok=True)\n",
    "    copied_count = 0\n",
    "    for fname in file_names:\n",
    "        source_path = os.path.join(source_img_dir, fname)\n",
    "        target_path = os.path.join(target_img_dir, fname)\n",
    "        if os.path.exists(source_path):\n",
    "            shutil.copy2(source_path, target_path)\n",
    "            copied_count += 1\n",
    "        else:\n",
    "            print(f\"[WARNING] ì›ë³¸ ì´ë¯¸ì§€ ì—†ìŒ: {source_path}\")\n",
    "    print(f\"ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ: {copied_count}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-23T15:11:12.380274Z",
     "iopub.status.busy": "2025-07-23T15:11:12.380035Z",
     "iopub.status.idle": "2025-07-23T15:11:12.393795Z",
     "shell.execute_reply": "2025-07-23T15:11:12.393098Z",
     "shell.execute_reply.started": "2025-07-23T15:11:12.380252Z"
    },
    "id": "ZvxUnOGaXpLJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬\n",
    "def split_train_val(image_dir, label_dir, train_img_dir, val_img_dir, train_label_dir, val_label_dir, val_ratio=0.15, seed=42):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ì™€ ë¼ë²¨ ë°ì´í„°ë¥¼ í•™ìŠµìš©(train)ê³¼ ê²€ì¦ìš©(val)ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ê°ê°ì˜ ë””ë ‰í† ë¦¬ë¡œ ì´ë™ì‹œí‚µë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        image_dir (str): ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "        label_dir (str): ì›ë³¸ ë¼ë²¨(txt) íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "        train_img_dir (str): í•™ìŠµìš© ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬.\n",
    "        val_img_dir (str): ê²€ì¦ìš© ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬.\n",
    "        train_label_dir (str): í•™ìŠµìš© ë¼ë²¨ ì €ì¥ ë””ë ‰í† ë¦¬.\n",
    "        val_label_dir (str): ê²€ì¦ìš© ë¼ë²¨ ì €ì¥ ë””ë ‰í† ë¦¬.\n",
    "        val_ratio (float, optional): ì „ì²´ ë°ì´í„° ì¤‘ ê²€ì¦ ë°ì´í„° ë¹„ìœ¨. ê¸°ë³¸ê°’ì€ 0.15.\n",
    "        seed (int, optional): ë°ì´í„° ë¶„í• ì„ ìœ„í•œ ëœë¤ ì‹œë“œ. ê¸°ë³¸ê°’ì€ 42.\n",
    "\n",
    "    Returns:\n",
    "        None. ì´ë¯¸ì§€ì™€ ë¼ë²¨ íŒŒì¼ì´ ì§€ì •ëœ ë””ë ‰í† ë¦¬ë¡œ ì´ë™ë©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    os.makedirs(train_img_dir, exist_ok=True)\n",
    "    os.makedirs(val_img_dir, exist_ok=True)\n",
    "    os.makedirs(train_label_dir, exist_ok=True)\n",
    "    os.makedirs(val_label_dir, exist_ok=True)\n",
    "\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    image_files.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    val_count = int(len(image_files) * val_ratio)\n",
    "    val_images = set(image_files[:val_count])\n",
    "    train_images = set(image_files[val_count:])\n",
    "\n",
    "    for img_file in image_files:\n",
    "        label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "\n",
    "        src_img_path = os.path.join(image_dir, img_file)\n",
    "        src_label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "        if img_file in val_images:\n",
    "            dst_img_path = os.path.join(val_img_dir, img_file)\n",
    "            dst_label_path = os.path.join(val_label_dir, label_file)\n",
    "        else:\n",
    "            dst_img_path = os.path.join(train_img_dir, img_file)\n",
    "            dst_label_path = os.path.join(train_label_dir, label_file)\n",
    "\n",
    "        # ë³µì‚¬ â†’ ì´ë™\n",
    "        if os.path.exists(src_img_path):\n",
    "            shutil.move(src_img_path, dst_img_path)\n",
    "\n",
    "        if os.path.exists(src_label_path):\n",
    "            shutil.move(src_label_path, dst_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "O3q6elpU-TEU"
   },
   "outputs": [],
   "source": [
    "# @title í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬\n",
    "def split_by_class(image_dir, label_dir, train_img_dir, val_img_dir, train_label_dir, val_label_dir, val_ratio=0.15, seed=42):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ì™€ YOLO ë¼ë²¨ ë°ì´í„°ë¥¼ í´ë˜ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ í•™ìŠµ/ê²€ì¦ ì„¸íŠ¸ë¡œ ë¶„ë¦¬í•˜ì—¬\n",
    "    í´ë˜ìŠ¤ë³„ë¡œ ë””ë ‰í† ë¦¬ì— ì •ë¦¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        image_dir (str): ì›ë³¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "        label_dir (str): ì›ë³¸ ë¼ë²¨(txt) ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "        train_img_dir (str): í•™ìŠµ ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬.\n",
    "        val_img_dir (str): ê²€ì¦ ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬.\n",
    "        train_label_dir (str): í•™ìŠµ ë¼ë²¨ ì €ì¥ ë””ë ‰í† ë¦¬.\n",
    "        val_label_dir (str): ê²€ì¦ ë¼ë²¨ ì €ì¥ ë””ë ‰í† ë¦¬.\n",
    "        val_ratio (float, optional): ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.15).\n",
    "        seed (int, optional): ëœë¤ ì‹œë“œ (ê¸°ë³¸ê°’: 42).\n",
    "\n",
    "    Returns:\n",
    "        None. í´ë˜ìŠ¤ë³„ë¡œ ë¶„ë¦¬ëœ ì´ë¯¸ì§€ ë° ë¼ë²¨ íŒŒì¼ì´ ê° ë””ë ‰í† ë¦¬ì— ì´ë™ë©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    os.makedirs(train_img_dir, exist_ok=True)\n",
    "    os.makedirs(val_img_dir, exist_ok=True)\n",
    "    os.makedirs(train_label_dir, exist_ok=True)\n",
    "    os.makedirs(val_label_dir, exist_ok=True)\n",
    "\n",
    "    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    image_files.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # ê° í´ë˜ìŠ¤ë³„ë¡œ ì´ë¯¸ì§€ íŒŒì¼ì„ ë‚˜ëˆŒ ì¤€ë¹„\n",
    "    class_train_images = defaultdict(list)\n",
    "    class_val_images = defaultdict(list)\n",
    "\n",
    "    # ì´ë¯¸ì§€ ë¶„ë¦¬ ë¹„ìœ¨ì— ë§ì¶°ì„œ í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• \n",
    "    val_count = int(len(image_files) * val_ratio)\n",
    "    val_images = set(image_files[:val_count])\n",
    "    train_images = set(image_files[val_count:])\n",
    "\n",
    "    # ê° ì´ë¯¸ì§€ì— í•´ë‹¹í•˜ëŠ” ë¼ë²¨ íŒŒì¼ ë¶„ë¦¬\n",
    "    for img_file in image_files:\n",
    "        label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "\n",
    "        # ë¼ë²¨ íŒŒì¼ì„ ì½ì–´ì„œ í´ë˜ìŠ¤ ì •ë³´ë¥¼ ì¶”ì¶œ\n",
    "        src_img_path = os.path.join(image_dir, img_file)\n",
    "        src_label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "        # ë¼ë²¨ì´ ì¡´ì¬í•˜ë©´ í•´ë‹¹ í´ë˜ìŠ¤ë“¤ì„ ì¶”ì¶œ\n",
    "        if os.path.exists(src_label_path):\n",
    "            with open(src_label_path, 'r') as f:\n",
    "                classes = [line.strip().split()[0] for line in f.readlines()]\n",
    "\n",
    "            # í´ë˜ìŠ¤ë³„ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜\n",
    "            for cls in classes:\n",
    "                if img_file in val_images:\n",
    "                    class_val_images[cls].append(img_file)\n",
    "                else:\n",
    "                    class_train_images[cls].append(img_file)\n",
    "\n",
    "    # ì´ë¯¸ì§€ íŒŒì¼ì„ í´ë˜ìŠ¤ë³„ë¡œ ë³µì‚¬\n",
    "    def move_files(class_images, source_img_dir, source_label_dir, target_img_dir, target_label_dir):\n",
    "        \"\"\"\n",
    "        í´ë˜ìŠ¤ë³„ë¡œ ì´ë¯¸ì§€ì™€ ë¼ë²¨ íŒŒì¼ì„ ì§€ì •ëœ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•©ë‹ˆë‹¤.\n",
    "\n",
    "        Args:\n",
    "            class_images (dict): í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬.\n",
    "            source_img_dir (str): ì›ë³¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "            source_label_dir (str): ì›ë³¸ ë¼ë²¨ ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "            target_img_dir (str): íƒ€ê²Ÿ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "            target_label_dir (str): íƒ€ê²Ÿ ë¼ë²¨ ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        for cls, img_files in class_images.items():\n",
    "            cls_img_dir = os.path.join(target_img_dir, cls)\n",
    "            cls_label_dir = os.path.join(target_label_dir, cls)\n",
    "            os.makedirs(cls_img_dir, exist_ok=True)\n",
    "            os.makedirs(cls_label_dir, exist_ok=True)\n",
    "\n",
    "            for img_file in img_files:\n",
    "                label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "\n",
    "                # ì´ë¯¸ì§€ íŒŒì¼ ì´ë™\n",
    "                src_img_path = os.path.join(source_img_dir, img_file)\n",
    "                dst_img_path = os.path.join(cls_img_dir, img_file)\n",
    "                shutil.move(src_img_path, dst_img_path)\n",
    "\n",
    "                # ë¼ë²¨ íŒŒì¼ ì´ë™\n",
    "                src_label_path = os.path.join(source_label_dir, label_file)\n",
    "                dst_label_path = os.path.join(cls_label_dir, label_file)\n",
    "                shutil.move(src_label_path, dst_label_path)\n",
    "\n",
    "    # í•™ìŠµ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„°ì— ëŒ€í•´ í´ë˜ìŠ¤ë³„ë¡œ íŒŒì¼ ì´ë™\n",
    "    move_files(class_train_images, image_dir, label_dir, train_img_dir, train_label_dir)\n",
    "    move_files(class_val_images, image_dir, label_dir, val_img_dir, val_label_dir)\n",
    "\n",
    "    print(\"í´ë˜ìŠ¤ë³„ë¡œ ì´ë¯¸ì§€ì™€ ë¼ë²¨ íŒŒì¼ì´ ë¶„ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-23T15:11:12.411165Z",
     "iopub.status.busy": "2025-07-23T15:11:12.410962Z",
     "iopub.status.idle": "2025-07-23T15:11:12.422022Z",
     "shell.execute_reply": "2025-07-23T15:11:12.421363Z",
     "shell.execute_reply.started": "2025-07-23T15:11:12.411148Z"
    },
    "id": "Z9iKDC5zXpLK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title ì´ë¯¸ì§€íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "def get_image_files_from_coco_json(json_path):\n",
    "    \"\"\"\n",
    "    COCO í˜•ì‹ì˜ JSON íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        json_path (str): COCO JSON ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ê²½ë¡œ.\n",
    "\n",
    "    Returns:\n",
    "        list: ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ë“¤ì´ ë‹´ê¸´ ë¦¬ìŠ¤íŠ¸.\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    image_files = [img['file_name'] for img in data.get('images', [])]\n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-23T15:11:12.422889Z",
     "iopub.status.busy": "2025-07-23T15:11:12.422715Z",
     "iopub.status.idle": "2025-07-23T15:11:12.435351Z",
     "shell.execute_reply": "2025-07-23T15:11:12.434717Z",
     "shell.execute_reply.started": "2025-07-23T15:11:12.422876Z"
    },
    "id": "kgCfAVfmXpLK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title ì¹´í…Œê³ ë¦¬ id, name ë§¤í•‘\n",
    "def get_master_categories(json_paths):\n",
    "    \"\"\"\n",
    "    COCO JSON íŒŒì¼ë“¤ì—ì„œ category idì™€ name ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        json_paths (list): COCO ì–´ë…¸í…Œì´ì…˜ JSON íŒŒì¼ ê²½ë¡œë“¤ì˜ ë¦¬ìŠ¤íŠ¸.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - cat_id_to_index (dict): ì •ë ¬ëœ category IDë¥¼ ê¸°ì¤€ìœ¼ë¡œ 0ë¶€í„° ì‹œì‘í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë§¤í•‘í•œ ë”•ì…”ë„ˆë¦¬.\n",
    "            - cat_id_to_name (dict): category IDë¥¼ category ì´ë¦„ìœ¼ë¡œ ë§¤í•‘í•œ ë”•ì…”ë„ˆë¦¬.\n",
    "    \"\"\"\n",
    "    cat_id_to_name = {}\n",
    "    for path in json_paths:\n",
    "        with open(path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        for cat in data['categories']:\n",
    "            cat_id_to_name[cat['id']] = cat['name']\n",
    "\n",
    "    sorted_cat_ids = sorted(cat_id_to_name.keys())\n",
    "    cat_id_to_index = {cat_id: idx for idx, cat_id in enumerate(sorted_cat_ids)}\n",
    "    return cat_id_to_index, cat_id_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-23T15:11:12.436230Z",
     "iopub.status.busy": "2025-07-23T15:11:12.436019Z",
     "iopub.status.idle": "2025-07-23T15:11:12.444888Z",
     "shell.execute_reply": "2025-07-23T15:11:12.444180Z",
     "shell.execute_reply.started": "2025-07-23T15:11:12.436207Z"
    },
    "id": "wR6dHLoWXpLK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title coco í˜•ì‹ì˜ ì–´ë…¸í…Œì´ì…˜ ì •ë³´ yolo í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "def convert_coco_to_yolo(annotation_file, source_img_dir, target_yolo_dir, master_cat_id_to_idx):\n",
    "    \"\"\"\n",
    "    COCO í˜•ì‹ì˜ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ì„ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        annotation_file (str): COCO JSON ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ê²½ë¡œ.\n",
    "        source_img_dir (str): ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "        target_yolo_dir (str): ë³€í™˜ëœ YOLO ë¼ë²¨(txt) íŒŒì¼ë“¤ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "        master_cat_id_to_idx (dict): COCO category_idë¥¼ YOLO í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë§¤í•‘í•œ ë”•ì…”ë„ˆë¦¬.\n",
    "\n",
    "    Returns:\n",
    "        None. YOLO ë¼ë²¨ íŒŒì¼ë“¤ì´ target_yolo_dirì— ì €ì¥ë©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    os.makedirs(target_yolo_dir, exist_ok=True)\n",
    "    with open(annotation_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    img_id_to_file = {img['id']: img['file_name'] for img in data['images']}\n",
    "    anns_per_img = defaultdict(list)\n",
    "    for ann in data['annotations']:\n",
    "        anns_per_img[ann['image_id']].append(ann)\n",
    "\n",
    "    for img_id, anns in anns_per_img.items():\n",
    "        img_file = img_id_to_file[img_id]\n",
    "        label_path = os.path.join(target_yolo_dir, img_file.rsplit('.', 1)[0] + \".txt\")\n",
    "        image_path = os.path.join(source_img_dir, img_file)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"[ê²½ê³ ] ì´ë¯¸ì§€ ì—†ìŒ: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        img = Image.open(image_path)\n",
    "        width, height = img.size\n",
    "\n",
    "        with open(label_path, 'w', encoding='utf-8') as f:\n",
    "            for ann in anns:\n",
    "                x, y, w, h = ann['bbox']\n",
    "                xc = (x + w / 2) / width\n",
    "                yc = (y + h / 2) / height\n",
    "                wn = w / width\n",
    "                hn = h / height\n",
    "                cls_idx = master_cat_id_to_idx.get(ann['category_id'], None)\n",
    "                if cls_idx is None:\n",
    "                    print(f\"[ê²½ê³ ] category_id {ann['category_id']}ê°€ master categoriesì— ì—†ìŒ\")\n",
    "                    continue\n",
    "                f.write(f\"{cls_idx} {xc:.6f} {yc:.6f} {wn:.6f} {hn:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-23T15:11:12.445843Z",
     "iopub.status.busy": "2025-07-23T15:11:12.445620Z",
     "iopub.status.idle": "2025-07-23T15:11:12.458599Z",
     "shell.execute_reply": "2025-07-23T15:11:12.457812Z",
     "shell.execute_reply.started": "2025-07-23T15:11:12.445821Z"
    },
    "id": "MeWtSThmXpLK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title ì™„ì „ë¼ë²¨ ë°ì´í„°(ì•½ë¬¼ìˆ˜ == annotationìˆ˜) ë‚¨ê¸°ê³  image/annotationíŒŒì¼ ì‚­ì œ\n",
    "def count_drugs_from_filename(filename):\n",
    "    \"\"\"\n",
    "    íŒŒì¼ ì´ë¦„ì—ì„œ ì•½ë¬¼ ê°œìˆ˜ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    ì˜ˆ: \"K-003351-020238-033880_...\" â†’ ì•½ë¬¼ ê°œìˆ˜: 3\n",
    "\n",
    "    Args:\n",
    "        filename (str): ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„.\n",
    "\n",
    "    Returns:\n",
    "        int: ì¶”ì •ëœ ì•½ë¬¼ ê°œìˆ˜ (í•˜ì´í”ˆìœ¼ë¡œ êµ¬ë¶„ëœ prefix ê¸°ì¤€).\n",
    "    \"\"\"\n",
    "    prefix = filename.split('_')[0] # prefix ì¶”ì¶œ\n",
    "\n",
    "    # 'K-' ì ‘ë‘ì–´ ì œê±°\n",
    "    if prefix.startswith(\"K-\"):\n",
    "        prefix = prefix[2:]\n",
    "\n",
    "    return len(prefix.split('-'))\n",
    "\n",
    "def clean_invalid_yolo_files_from_dir(merged_json_path, image_dir, label_dir):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ íŒŒì¼ì—ì„œ ì•½ë¬¼ ê°œìˆ˜(íŒŒì¼ëª… ê¸°ë°˜)ì™€ COCO ì–´ë…¸í…Œì´ì…˜ ë‚´ ì‹¤ì œ annotation ìˆ˜(category ìˆ˜)ë¥¼ ë¹„êµí•˜ì—¬,\n",
    "    ë¶ˆì™„ì „í•œ ì´ë¯¸ì§€ ë° ë¼ë²¨ íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        merged_json_path (str): ë³‘í•©ëœ COCO ì–´ë…¸í…Œì´ì…˜ JSON íŒŒì¼ ê²½ë¡œ.\n",
    "        image_dir (str): ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬.\n",
    "        label_dir (str): ë¼ë²¨(.json) íŒŒì¼ë“¤ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ (í•˜ìœ„ í´ë” í¬í•¨).\n",
    "\n",
    "    Returns:\n",
    "        None. ì¡°ê±´ì— ë§ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ ë° í•´ë‹¹ ë¼ë²¨ íŒŒì¼ì´ ì‚­ì œë©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(merged_json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(\"ğŸ“‚ JSON ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "    file_to_id = {img[\"file_name\"]: img[\"id\"] for img in data[\"images\"]}\n",
    "\n",
    "    image_id_to_cat_ids = defaultdict(set)\n",
    "    for ann in data[\"annotations\"]:\n",
    "        image_id_to_cat_ids[ann[\"image_id\"]].add(ann[\"category_id\"])\n",
    "\n",
    "    removed = 0\n",
    "    print(f\"ğŸ” ê²€ì‚¬ ì¤‘: {image_dir} / {label_dir}\")\n",
    "\n",
    "    for fname in os.listdir(image_dir):\n",
    "        if not fname.endswith(\".png\"):\n",
    "            continue\n",
    "\n",
    "        base_name = os.path.splitext(fname)[0]\n",
    "        full_name = fname\n",
    "        drug_count = count_drugs_from_filename(fname)\n",
    "\n",
    "        image_id = file_to_id.get(full_name)\n",
    "        if image_id is None:\n",
    "            print(f\"âš ï¸ JSONì— ì—†ìŒ: {full_name}\")\n",
    "            continue\n",
    "\n",
    "        actual_category_count = len(image_id_to_cat_ids[image_id])\n",
    "\n",
    "        if actual_category_count < drug_count:\n",
    "            # ì´ë¯¸ì§€ ì‚­ì œ\n",
    "            img_path = os.path.join(image_dir, full_name)\n",
    "            if os.path.exists(img_path):\n",
    "                os.remove(img_path)\n",
    "                print(f\"ğŸ—‘ï¸ ì´ë¯¸ì§€ ì‚­ì œ: {img_path}\")\n",
    "\n",
    "            # label_dir ì•„ë˜ ëª¨ë“  í•˜ìœ„ í´ë”ì—ì„œ .json ì‚­ì œ\n",
    "            json_pattern = os.path.join(label_dir, \"**\", base_name + \".json\")\n",
    "            json_paths = glob.glob(json_pattern, recursive=True)\n",
    "\n",
    "            for json_path in json_paths:\n",
    "                if os.path.exists(json_path):\n",
    "                    os.remove(json_path)\n",
    "                    print(f\"ğŸ—‘ï¸ JSON ì‚­ì œ: {json_path}\")\n",
    "\n",
    "            removed += 1\n",
    "\n",
    "    print(f\"\\nâœ… ì´ ì‚­ì œëœ í•­ëª© ìˆ˜: {removed}ê°œ\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-23T15:11:14.797719Z",
     "iopub.status.busy": "2025-07-23T15:11:14.797204Z",
     "iopub.status.idle": "2025-07-23T15:11:14.827994Z",
     "shell.execute_reply": "2025-07-23T15:11:14.827509Z",
     "shell.execute_reply.started": "2025-07-23T15:11:14.797697Z"
    },
    "id": "8uGpovnjXpLL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜ ê³„ì‚°\n",
    "def count_classes_in_yolo_txt(labels_dir):\n",
    "    \"\"\"\n",
    "    YOLO í˜•ì‹ì˜ ë¼ë²¨ íŒŒì¼ì„ ì½ì–´ í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜ ê³„ì‚°\n",
    "\n",
    "    Args:\n",
    "        labels_dir (str): ë¼ë²¨ íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "\n",
    "    Returns:\n",
    "        class_count (dict): í´ë˜ìŠ¤ IDë³„ë¡œ ì´ë¯¸ì§€ ìˆ˜ë¥¼ ì¹´ìš´íŠ¸í•œ ë”•ì…”ë„ˆë¦¬.\n",
    "    \"\"\"\n",
    "    class_count = defaultdict(int)  # ê° í´ë˜ìŠ¤ë³„ ì¹´ìš´íŠ¸ë¥¼ ì €ì¥í•˜ëŠ” ë”•ì…”ë„ˆë¦¬\n",
    "\n",
    "    for root, _, files in os.walk(labels_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                label_path = os.path.join(root, file)\n",
    "\n",
    "                with open(label_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    for line in lines:\n",
    "                        parts = line.strip().split()  # YOLO í¬ë§·ì—ì„œ í•œ ì¤„ì„ ê³µë°±ìœ¼ë¡œ ë‚˜ëˆ„ê¸°\n",
    "                        if len(parts) >= 1:\n",
    "                            try:\n",
    "                                class_id = int(float(parts[0]))\n",
    "                            except ValueError:\n",
    "                                print(f\"[ê²½ê³ ] í´ë˜ìŠ¤ ID ë³€í™˜ ì‹¤íŒ¨: {parts[0]} in {file}\")\n",
    "                                continue\n",
    "                            class_count[class_id] += 1  # í•´ë‹¹ í´ë˜ìŠ¤ IDì— ëŒ€í•œ ì¹´ìš´íŠ¸ ì¦ê°€\n",
    "\n",
    "    return class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-23T15:11:14.828781Z",
     "iopub.status.busy": "2025-07-23T15:11:14.828571Z",
     "iopub.status.idle": "2025-07-23T15:11:14.842101Z",
     "shell.execute_reply": "2025-07-23T15:11:14.841575Z",
     "shell.execute_reply.started": "2025-07-23T15:11:14.828762Z"
    },
    "id": "d1jR6lIKXpLL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title ì´ë¯¸ì§€, ë¼ë²¨ ê°œìˆ˜ í™•ì¸\n",
    "def check_images_labels(img_dir, labels_dir):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ì™€ ë¼ë²¨ ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼ ìˆ˜ë¥¼ ë¹„êµí•˜ê³ ,\n",
    "    ì´ë¯¸ì§€ì— ëŒ€ì‘í•˜ëŠ” ë¼ë²¨ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ë° ë¼ë²¨ì— ëŒ€ì‘í•˜ëŠ” ì´ë¯¸ì§€ ì¡´ì¬ ì—¬ë¶€ë¥¼ ê²€ì‚¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        img_dir (str): ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "        labels_dir (str): YOLO í˜•ì‹ ë¼ë²¨(.txt) íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ.\n",
    "\n",
    "    Returns:\n",
    "        bool: ì´ë¯¸ì§€ì™€ ë¼ë²¨ì´ ì™„ë²½íˆ ë§¤ì¹­ë˜ë©´ True, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ False.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(labels_dir):\n",
    "        print(f\"âŒ ë¼ë²¨ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {labels_dir}\")\n",
    "        return False\n",
    "\n",
    "    # ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ (í™•ì¥ì ë¬´ì‹œí•˜ê³  ì´ë¦„ë§Œ ì¶”ì¶œ)\n",
    "    img_files = [f for f in os.listdir(img_dir) if f.lower().endswith('.png')]\n",
    "    img_names = set(os.path.splitext(f)[0] for f in img_files)\n",
    "\n",
    "    # ë¼ë²¨ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ (í™•ì¥ì ë¬´ì‹œí•˜ê³  ì´ë¦„ë§Œ ì¶”ì¶œ)\n",
    "    label_files = [f for f in os.listdir(labels_dir) if f.endswith('.txt')]\n",
    "    label_names = set(os.path.splitext(f)[0] for f in label_files)\n",
    "\n",
    "    print(f\"ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: {len(img_files)}\")\n",
    "    print(f\"ë¼ë²¨ íŒŒì¼ ê°œìˆ˜: {len(label_files)}\")\n",
    "\n",
    "    # ì´ë¯¸ì§€ì— ë§¤í•‘ë˜ëŠ” ë¼ë²¨ ì—†ëŠ” íŒŒì¼ë“¤\n",
    "    missing_labels = img_names - label_names\n",
    "    # ë¼ë²¨ì— ë§¤í•‘ë˜ëŠ” ì´ë¯¸ì§€ ì—†ëŠ” íŒŒì¼ë“¤ (ë¼ë²¨ë§Œ ìˆëŠ” ê²½ìš°)\n",
    "    missing_images = label_names - img_names\n",
    "\n",
    "    if missing_labels:\n",
    "        print(f\"âŒ ë¼ë²¨ì´ ì—†ëŠ” ì´ë¯¸ì§€ íŒŒì¼ ({len(missing_labels)}ê°œ):\")\n",
    "        for name in sorted(missing_labels):\n",
    "            print(f\"  - {name}\")\n",
    "    else:\n",
    "        print(\"âœ… ëª¨ë“  ì´ë¯¸ì§€ì— ëŒ€ì‘í•˜ëŠ” ë¼ë²¨ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    if missing_images:\n",
    "        print(f\"âš ï¸ ë¼ë²¨ì€ ìˆìœ¼ë‚˜ ì´ë¯¸ì§€ê°€ ì—†ëŠ” íŒŒì¼ ({len(missing_images)}ê°œ):\")\n",
    "        for name in sorted(missing_images):\n",
    "            print(f\"  - {name}\")\n",
    "    else:\n",
    "        print(\"âœ… ëª¨ë“  ë¼ë²¨ íŒŒì¼ì— ëŒ€ì‘í•˜ëŠ” ì´ë¯¸ì§€ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    return len(missing_labels) == 0 and len(missing_images) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "e1ASinkK9pIc"
   },
   "outputs": [],
   "source": [
    "# @title ì´ë¯¸ì§€ ì¦ê°•\n",
    "def yolo_to_xyxy(bbox, img_w, img_h):\n",
    "    \"\"\"\n",
    "    YOLO í˜•ì‹ì˜ bbox(x_center, y_center, width, height, normalized)ë¥¼\n",
    "    ì¢Œí‘œ (x1, y1, x2, y2, ì ˆëŒ€ í”½ì…€ ë‹¨ìœ„)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        bbox (list): [x_center, y_center, width, height] (0~1 ì‚¬ì´ ì •ê·œí™”ëœ ê°’)\n",
    "        img_w (int): ì´ë¯¸ì§€ ë„ˆë¹„ (í”½ì…€)\n",
    "        img_h (int): ì´ë¯¸ì§€ ë†’ì´ (í”½ì…€)\n",
    "\n",
    "    Returns:\n",
    "        list: [x1, y1, x2, y2] ì ˆëŒ€ ì¢Œí‘œ\n",
    "    \"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    x1 = (x - w / 2) * img_w\n",
    "    y1 = (y - h / 2) * img_h\n",
    "    x2 = (x + w / 2) * img_w\n",
    "    y2 = (y + h / 2) * img_h\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def xyxy_to_yolo(bbox, img_w, img_h):\n",
    "    \"\"\"\n",
    "    bbox (x1, y1, x2, y2, ì ˆëŒ€ í”½ì…€ ë‹¨ìœ„)ë¥¼ YOLO í˜•ì‹ì˜\n",
    "    (x_center, y_center, width, height, normalized)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        bbox (list): [x1, y1, x2, y2] ì ˆëŒ€ ì¢Œí‘œ\n",
    "        img_w (int): ì´ë¯¸ì§€ ë„ˆë¹„ (í”½ì…€)\n",
    "        img_h (int): ì´ë¯¸ì§€ ë†’ì´ (í”½ì…€)\n",
    "\n",
    "    Returns:\n",
    "        list: [x_center, y_center, width, height] (0~1 ì‚¬ì´ ì •ê·œí™”ëœ ê°’)\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    x = ((x1 + x2) / 2) / img_w\n",
    "    y = ((y1 + y2) / 2) / img_h\n",
    "    w = (x2 - x1) / img_w\n",
    "    h = (y2 - y1) / img_h\n",
    "    return [x, y, w, h]\n",
    "\n",
    "# ì¦ê°• ê¸°ë²• ë¦¬ìŠ¤íŠ¸ (Albumentations ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)\n",
    "AUGMENTATIONS = [\n",
    "    A.Compose([A.HorizontalFlip(p=1.0)]),\n",
    "    A.Compose([A.VerticalFlip(p=1.0)]),\n",
    "    A.Compose([A.RandomBrightnessContrast(p=1.0)]),\n",
    "    A.Compose([A.Rotate(limit=25, p=1.0)]),\n",
    "    A.Compose([A.GaussianBlur(p=1.0)]),\n",
    "    A.Compose([A.ColorJitter(p=1.0)]),\n",
    "    A.Compose([A.RandomGamma(p=1.0)])\n",
    "]\n",
    "\n",
    "def copy_few_shot_images(\n",
    "    yolo_img_dir, yolo_label_dir,\n",
    "    cat_id_to_name,\n",
    "    max_classes_threshold=75,\n",
    "    top_n=10,\n",
    "    padding_ratio=0\n",
    "):\n",
    "    \"\"\"\n",
    "    í¬ì†Œ í´ë˜ìŠ¤(ì¶œí˜„ ë¹ˆë„ê°€ ì ì€ í´ë˜ìŠ¤)ì— ëŒ€í•´ ì´ë¯¸ì§€ ì¦ê°•ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    - ìƒìœ„ top_n í´ë˜ìŠ¤ëŠ” ì¦ê°• ì œì™¸(ë˜ëŠ” í¬ë¡­ ì¦ê°• ì œì™¸).\n",
    "    - í¬ì†Œ í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜ê°€ max_classes_thresholdë¥¼ ë„˜ë„ë¡ ì¦ê°• ì§„í–‰.\n",
    "    - ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í¬ë¡­ ë° ì—¬ëŸ¬ ë³€í™˜ì„ ì ìš©í•´ ì¦ê°• ì´ë¯¸ì§€ ìƒì„±.\n",
    "\n",
    "    Args:\n",
    "        yolo_img_dir (str): YOLO ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ\n",
    "        yolo_label_dir (str): YOLO ë¼ë²¨(.txt) íŒŒì¼ ê²½ë¡œ\n",
    "        cat_id_to_name (dict): í´ë˜ìŠ¤ ID â†’ í´ë˜ìŠ¤ ì´ë¦„ ë§¤í•‘\n",
    "        max_classes_threshold (int): ê° í´ë˜ìŠ¤ë³„ ìµœëŒ€ ì¦ê°• ì´ë¯¸ì§€ ê°œìˆ˜\n",
    "        top_n (int): ì¦ê°•ì—ì„œ ì œì™¸í•  ìƒìœ„ ë¹ˆë„ í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "        padding_ratio (float): í¬ë¡­ ì˜ì—­ ì£¼ë³€ padding ë¹„ìœ¨ (0ì´ë©´ íŒ¨ë”© ì—†ìŒ)\n",
    "\n",
    "    Returns:\n",
    "        None. ì¦ê°•ëœ ì´ë¯¸ì§€ ë° ë¼ë²¨ íŒŒì¼ì„ ì§€ì • ê²½ë¡œì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    os.makedirs(yolo_img_dir, exist_ok=True)\n",
    "    os.makedirs(yolo_label_dir, exist_ok=True)\n",
    "\n",
    "    class_img_map = defaultdict(set)\n",
    "    img_class_map = defaultdict(set)\n",
    "\n",
    "    # í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€, ì´ë¯¸ì§€ë³„ í´ë˜ìŠ¤ ì´ˆê¸°í™”\n",
    "    for label_fname in os.listdir(yolo_label_dir):\n",
    "        if not label_fname.endswith(\".txt\"):\n",
    "            continue\n",
    "        base_name = os.path.splitext(label_fname)[0]\n",
    "        label_path = os.path.join(yolo_label_dir, label_fname)\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                cls_id = int(parts[0])\n",
    "                class_img_map[cls_id].add(base_name)\n",
    "                img_class_map[base_name].add(cls_id)\n",
    "\n",
    "    class_counts = {cid: len(imgs) for cid, imgs in class_img_map.items()}\n",
    "    top_n_classes = set(heapq.nlargest(top_n, class_counts, key=class_counts.get))\n",
    "\n",
    "    few_classes = {\n",
    "        cid: list(imgs)\n",
    "        for cid, imgs in class_img_map.items()\n",
    "        if (len(imgs) <= max_classes_threshold and cid not in top_n_classes)\n",
    "    }\n",
    "\n",
    "    sorted_few_class_ids = sorted(few_classes.keys(), key=lambda x: class_counts[x])\n",
    "\n",
    "    def crop_and_save(image, bbox, cls_id, base_name, count):\n",
    "        h, w = image.shape[:2]\n",
    "        x1, y1, x2, y2 = bbox\n",
    "\n",
    "        pad_x = int((x2 - x1) * padding_ratio)\n",
    "        pad_y = int((y2 - y1) * padding_ratio)\n",
    "\n",
    "        x1 = max(0, int(x1 - pad_x))\n",
    "        y1 = max(0, int(y1 - pad_y))\n",
    "        x2 = min(w, int(x2 + pad_x))\n",
    "        y2 = min(h, int(y2 + pad_y))\n",
    "\n",
    "        cropped = image[y1:y2, x1:x2]\n",
    "\n",
    "        new_x, new_y, new_w, new_h = 0.5, 0.5, 1.0, 1.0\n",
    "        yolo_line = f\"{cls_id} {new_x:.6f} {new_y:.6f} {new_w:.6f} {new_h:.6f}\"\n",
    "\n",
    "        new_base = f\"{base_name}_aug{count}\"\n",
    "        new_img_path = os.path.join(yolo_img_dir, new_base + \".png\")\n",
    "        new_label_path = os.path.join(yolo_label_dir, new_base + \".txt\")\n",
    "        cv2.imwrite(new_img_path, cropped)\n",
    "        with open(new_label_path, 'w') as f:\n",
    "            f.write(yolo_line + \"\\n\")\n",
    "\n",
    "        class_img_map[cls_id].add(new_base)\n",
    "        img_class_map[new_base] = {cls_id}\n",
    "\n",
    "        for i in range(5):\n",
    "            aug = random.choice(AUGMENTATIONS)\n",
    "            try:\n",
    "                aug_data = aug(image=cropped, bboxes=[[0.0, 0.0, 1.0, 1.0]], category_ids=[cls_id])\n",
    "                aug_img = aug_data['image']\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            aug_base = f\"{base_name}_aug{count}_crop{i}\"\n",
    "            aug_img_path = os.path.join(yolo_img_dir, aug_base + \".png\")\n",
    "            aug_label_path = os.path.join(yolo_label_dir, aug_base + \".txt\")\n",
    "            cv2.imwrite(aug_img_path, aug_img)\n",
    "            with open(aug_label_path, 'w') as f:\n",
    "                f.write(yolo_line + \"\\n\")\n",
    "\n",
    "            class_img_map[cls_id].add(aug_base)\n",
    "            img_class_map[aug_base] = {cls_id}\n",
    "\n",
    "    total_success_count = 0\n",
    "\n",
    "    for cid in sorted_few_class_ids:\n",
    "        img_list = few_classes[cid]\n",
    "        print(f\"\\nğŸ“ˆ í´ë˜ìŠ¤ {cid} ({cat_id_to_name.get(cid, cid)}), ëª©í‘œ ì¦ê°• ìˆ˜: {max_classes_threshold - len(img_list)}\")\n",
    "\n",
    "        img_cycle = cycle(img_list)\n",
    "        success_count = 0\n",
    "\n",
    "        while True:\n",
    "            current_count = len(class_img_map[cid])\n",
    "            if current_count >= max_classes_threshold:\n",
    "                break\n",
    "\n",
    "            current_counts = {cid_: len(imgs) for cid_, imgs in class_img_map.items()}\n",
    "            major_classes_set = set(heapq.nlargest(top_n, current_counts, key=current_counts.get))\n",
    "\n",
    "            base_name = next(img_cycle)\n",
    "            if \"_aug\" in base_name:\n",
    "                continue\n",
    "\n",
    "            image_path = os.path.join(yolo_img_dir, base_name + \".png\")\n",
    "            label_path = os.path.join(yolo_label_dir, base_name + \".txt\")\n",
    "            if not os.path.exists(image_path) or not os.path.exists(label_path):\n",
    "                continue\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            h, w = image.shape[:2]\n",
    "            bboxes, class_ids = [], []\n",
    "\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) != 5:\n",
    "                        continue\n",
    "                    cls, x, y, bw, bh = map(float, parts)\n",
    "                    bboxes.append(yolo_to_xyxy([x, y, bw, bh], w, h))\n",
    "                    class_ids.append(int(cls))\n",
    "\n",
    "            # 75ê°œ ì´ìƒ í´ë˜ìŠ¤ í¬í•¨ëœ ì´ë¯¸ì§€ í¬ë¡­ ì¦ê°• ì ìš©\n",
    "            if any(len(class_img_map[c]) >= max_classes_threshold for c in img_class_map[base_name]):\n",
    "                for box, cls in zip(bboxes, class_ids):\n",
    "                    if cls == cid:\n",
    "                        crop_and_save(image, box, cls, base_name, success_count)\n",
    "                        success_count += 1\n",
    "                        total_success_count += 1\n",
    "                        if len(class_img_map[cid]) >= max_classes_threshold:\n",
    "                            break\n",
    "                if len(class_img_map[cid]) >= max_classes_threshold:\n",
    "                    break\n",
    "            else:\n",
    "                aug = random.choice(AUGMENTATIONS)\n",
    "                try:\n",
    "                    aug_data = aug(image=image, bboxes=bboxes, category_ids=class_ids)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                aug_img = aug_data['image']\n",
    "                aug_bboxes = aug_data['bboxes']\n",
    "                aug_class_ids = aug_data['category_ids']\n",
    "\n",
    "                new_lines = []\n",
    "                for box, cls in zip(aug_bboxes, aug_class_ids):\n",
    "                    yolo_box = [max(0, min(1, v)) for v in xyxy_to_yolo(box, w, h)]\n",
    "                    new_lines.append(f\"{cls} {' '.join(f'{v:.6f}' for v in yolo_box)}\")\n",
    "\n",
    "                new_base = f\"{base_name}_aug{success_count}\"\n",
    "                new_img_path = os.path.join(yolo_img_dir, new_base + \".png\")\n",
    "                new_label_path = os.path.join(yolo_label_dir, new_base + \".txt\")\n",
    "\n",
    "                cv2.imwrite(new_img_path, aug_img)\n",
    "                with open(new_label_path, 'w') as f:\n",
    "                    f.write(\"\\n\".join(new_lines))\n",
    "\n",
    "                for c in set(aug_class_ids):\n",
    "                    class_img_map[c].add(new_base)\n",
    "                img_class_map[new_base] = set(aug_class_ids)\n",
    "\n",
    "                success_count += 1\n",
    "                total_success_count += 1\n",
    "\n",
    "    print(f\"\\nâœ… ì´ ì¦ê°•ëœ ì´ë¯¸ì§€ ìˆ˜: {total_success_count}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Jq-Ee5J1_GLs"
   },
   "outputs": [],
   "source": [
    "# @title í´ë˜ìŠ¤ë³„ ê¸°ì¤€ ê°œìˆ˜ë³´ë‹¤ ë§ì€ ì´ë¯¸ì§€ ì‚­ì œ\n",
    "def fine_tune_delete_by_class_popularity_relaxed(\n",
    "    yolo_img_dir, yolo_label_dir, target_count=75, margin=10\n",
    "):\n",
    "    \"\"\"\n",
    "    í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜ê°€ target_countë³´ë‹¤ ë§ì„ ê²½ìš°, marginë§Œí¼ ì™„í™”í•˜ì—¬\n",
    "    ì´ë¯¸ì§€ë“¤ì„ ì‚­ì œí•´ í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.\n",
    "    - ì´ë¯¸ì§€ì— ì—¬ëŸ¬ í´ë˜ìŠ¤ê°€ í¬í•¨ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‚­ì œ ì‹œ ëª¨ë“  í´ë˜ìŠ¤ì˜\n",
    "      ì´ë¯¸ì§€ ìˆ˜ê°€ target_count - margin ì´ìƒ ìœ ì§€ë˜ë„ë¡ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "    - ì‚­ì œ ìš°ì„ ìˆœìœ„ëŠ” í¬í•¨ëœ í´ë˜ìŠ¤ ê°œìˆ˜ê°€ ì ì€ ì´ë¯¸ì§€ë¶€í„° ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "    - ì‚­ì œ ì‹œ '_aug' í˜¹ì€ '_copy'ê°€ í¬í•¨ëœ íŒŒì¼ì„ ìš°ì„  ëœë¤ìœ¼ë¡œ ì‚­ì œí•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        yolo_img_dir (str): YOLO í˜•ì‹ ì´ë¯¸ì§€ê°€ ì €ì¥ëœ í´ë” ê²½ë¡œ.\n",
    "        yolo_label_dir (str): YOLO í˜•ì‹ ë¼ë²¨(.txt) íŒŒì¼ë“¤ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ.\n",
    "        target_count (int): í´ë˜ìŠ¤ë³„ ìµœì†Œ ìœ ì§€í•  ì´ë¯¸ì§€ ê°œìˆ˜ ê¸°ì¤€.\n",
    "        margin (int): target_count ëŒ€ë¹„ ì™„í™” í—ˆìš© ë²”ìœ„ (ì˜ˆ: target_count - margin ì´ìƒ ìœ ì§€).\n",
    "\n",
    "    Returns:\n",
    "        None. ì‚­ì œ ëŒ€ìƒ ì´ë¯¸ì§€ë¥¼ ì‹¤ì œ íŒŒì¼ì—ì„œ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    ext = \".png\"\n",
    "    image_to_classes = {}\n",
    "    class_counts = Counter()\n",
    "\n",
    "    for fname in os.listdir(yolo_img_dir):\n",
    "        if not fname.endswith(ext):\n",
    "            continue\n",
    "        base = os.path.splitext(fname)[0]\n",
    "        label_path = os.path.join(yolo_label_dir, base + \".txt\")\n",
    "        classes = set()\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path) as f:\n",
    "                for line in f:\n",
    "                    cls_id = line.split()[0]\n",
    "                    classes.add(cls_id)\n",
    "        image_to_classes[base] = classes\n",
    "        for cls in classes:\n",
    "            class_counts[cls] += 1\n",
    "\n",
    "    current_counts = class_counts.copy()\n",
    "    class_to_images = defaultdict(set)\n",
    "    for img, classes in image_to_classes.items():\n",
    "        for cls in classes:\n",
    "            class_to_images[cls].add(img)\n",
    "\n",
    "    to_delete = set()\n",
    "    classes_sorted = sorted(class_counts.keys(), key=lambda c: class_counts[c], reverse=True)\n",
    "\n",
    "    print(f\"ì´ˆê¸° í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ê°œìˆ˜: {dict(class_counts)}\")\n",
    "\n",
    "    for cls in classes_sorted:\n",
    "        if current_counts[cls] <= target_count:\n",
    "            continue\n",
    "\n",
    "        imgs_for_cls = list(class_to_images[cls] - to_delete)\n",
    "        imgs_for_cls.sort(key=lambda img: len(image_to_classes[img]))\n",
    "\n",
    "        for img in imgs_for_cls:\n",
    "            img_classes = image_to_classes[img]\n",
    "            # margin ë§Œí¼ ì™„í™”: ì‚­ì œ í›„ í´ë˜ìŠ¤ ê°œìˆ˜ê°€ target_count - margin ì´ìƒì´ë©´ OK\n",
    "            if all(current_counts[c] - 1 >= target_count - margin for c in img_classes):\n",
    "                to_delete.add(img)\n",
    "                for c in img_classes:\n",
    "                    current_counts[c] -= 1\n",
    "                if current_counts[cls] <= target_count:\n",
    "                    break\n",
    "\n",
    "    print(f\"\\nì‚­ì œ ì˜ˆì • ì´ë¯¸ì§€ ìˆ˜: {len(to_delete)}\")\n",
    "    print(f\"ì‚­ì œ í›„ ì˜ˆìƒ í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ê°œìˆ˜: {dict(current_counts)}\")\n",
    "\n",
    "    print(\"\\nì‚­ì œ ì§„í–‰ ì¤‘...\")\n",
    "\n",
    "    def has_special_suffix(base_name):\n",
    "        return ('_aug' in base_name) or ('_copy' in base_name)\n",
    "\n",
    "    special_files = [base for base in to_delete if has_special_suffix(base)]\n",
    "    normal_files = [base for base in to_delete if not has_special_suffix(base)]\n",
    "\n",
    "    random.shuffle(special_files)\n",
    "    random.shuffle(normal_files)\n",
    "\n",
    "    for base in special_files + normal_files:\n",
    "        img_path = os.path.join(yolo_img_dir, base + ext)\n",
    "        label_path = os.path.join(yolo_label_dir, base + \".txt\")\n",
    "        if os.path.exists(img_path):\n",
    "            os.remove(img_path)\n",
    "            print(f\"ì‚­ì œ: {img_path}\")\n",
    "        if os.path.exists(label_path):\n",
    "            os.remove(label_path)\n",
    "            print(f\"ì‚­ì œ: {label_path}\")\n",
    "\n",
    "    print(\"\\nì‚­ì œ ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "zHXBGC7v8UD_"
   },
   "outputs": [],
   "source": [
    "# @title yamlíŒŒì¼ ìƒì„±\n",
    "def create_yolo_yaml(root_dir, merged_json_path, yaml_path):\n",
    "    \"\"\"\n",
    "    YOLO í•™ìŠµì— ì‚¬ìš©í•  data.yaml íŒŒì¼ ìƒì„± í•¨ìˆ˜.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): ë°ì´í„°ì…‹ì˜ ë£¨íŠ¸ ê²½ë¡œ (train, val ê²½ë¡œ ê¸°ì¤€).\n",
    "        merged_json_path (str): ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•œ JSON íŒŒì¼ ê²½ë¡œ.\n",
    "        yaml_path (str): ìƒì„±í•  yaml íŒŒì¼ ê²½ë¡œ.\n",
    "\n",
    "    ë™ì‘:\n",
    "        - get_master_categories í•¨ìˆ˜ë¡œ ì¹´í…Œê³ ë¦¬ idì™€ ì´ë¦„, ì¸ë±ìŠ¤ ë§¤í•‘ ì •ë³´ë¥¼ ì–»ìŒ\n",
    "        - yaml í˜•ì‹ì— ë§ê²Œ train, val ê²½ë¡œ, í´ë˜ìŠ¤ ìˆ˜, í´ë˜ìŠ¤ ì´ë¦„ë“¤ì„ data.yaml íŒŒì¼ë¡œ ì €ì¥\n",
    "    \"\"\"\n",
    "    # ì¹´í…Œê³ ë¦¬ ì •ë³´ íšë“: cat_id_to_index (cat_id -> index), cat_id_to_name (cat_id -> í´ë˜ìŠ¤ëª…)\n",
    "    cat_id_to_index, cat_id_to_name = get_master_categories([merged_json_path])\n",
    "\n",
    "    # YOLO í´ë˜ìŠ¤ ì¸ë±ìŠ¤ â†’ í´ë˜ìŠ¤ëª… ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "    names_dict = {\n",
    "        idx: cat_id_to_name[cat_id]\n",
    "        for cat_id, idx in cat_id_to_index.items()\n",
    "    }\n",
    "\n",
    "    # yaml íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„± (ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´)\n",
    "    yaml_dir = os.path.dirname(yaml_path)\n",
    "    os.makedirs(yaml_dir, exist_ok=True)\n",
    "\n",
    "    # yaml íŒŒì¼ ìƒì„± ë° ì‘ì„±\n",
    "    with open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"path: {root_dir}\\n\")                     # ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ\n",
    "        f.write(f\"train: images/train_images\\n\")           # í•™ìŠµ ì´ë¯¸ì§€ ê²½ë¡œ (ë£¨íŠ¸ ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ)\n",
    "        f.write(f\"val: images/train_images\\n\")             # ê²€ì¦ ì´ë¯¸ì§€ ê²½ë¡œ (ë£¨íŠ¸ ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ)\n",
    "        f.write(f\"nc: {len(names_dict)}\\n\")                 # í´ë˜ìŠ¤ ìˆ˜\n",
    "        f.write(\"names:\\n\")                                 # í´ë˜ìŠ¤ ì´ë¦„ë“¤\n",
    "        for idx in range(len(names_dict)):\n",
    "            class_name = names_dict[idx]\n",
    "            f.write(f\"  {idx}: '{class_name}'\\n\")\n",
    "\n",
    "    print(f\"data.yaml íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNfvnxf6z-kt"
   },
   "source": [
    "## ì‹œê°í™” ë©”ì„œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-23T15:11:16.274743Z",
     "iopub.status.busy": "2025-07-23T15:11:16.274474Z",
     "iopub.status.idle": "2025-07-23T15:11:16.294210Z",
     "shell.execute_reply": "2025-07-23T15:11:16.293352Z",
     "shell.execute_reply.started": "2025-07-23T15:11:16.274721Z"
    },
    "id": "5IXkJchFXpLM",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title ë°”ìš´ë”© ë°•ìŠ¤ ì¤‘ë³µ/ê²¹ì¹¨ í™•ì¸\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    ë‘ ë°”ìš´ë”© ë°•ìŠ¤(box1, box2)ì˜ IoU(êµì§‘í•© / í•©ì§‘í•©)ë¥¼ ê³„ì‚°\n",
    "\n",
    "    Args:\n",
    "        box1, box2: [x1, y1, x2, y2] í˜•ì‹ì˜ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "    Returns:\n",
    "        IoU (float): 0.0 ~ 1.0 ì‚¬ì´ì˜ ê²¹ì¹¨ ë¹„ìœ¨\n",
    "    \"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    inter_w = max(0.0, x2 - x1)\n",
    "    inter_h = max(0.0, y2 - y1)\n",
    "    inter_area = inter_w * inter_h\n",
    "    area1 = max(0.0, (box1[2] - box1[0]) * (box1[3] - box1[1]))\n",
    "    area2 = max(0.0, (box2[2] - box2[0]) * (box2[3] - box2[1]))\n",
    "    union_area = area1 + area2 - inter_area\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "    return inter_area / union_area\n",
    "\n",
    "def xywh_to_xyxy(bbox):\n",
    "    \"\"\"\n",
    "    [x, y, w, h] í˜•íƒœì˜ bboxë¥¼ [x1, y1, x2, y2] í˜•íƒœë¡œ ë³€í™˜\n",
    "\n",
    "    Args:\n",
    "        bbox: [x, y, w, h]\n",
    "\n",
    "    Returns:\n",
    "        [x1, y1, x2, y2]\n",
    "    \"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "def merge_all_jsons_recursive(json_folder):\n",
    "    \"\"\"\n",
    "    json_folder ë‚´ ëª¨ë“  JSON íŒŒì¼ì„ ì¬ê·€ì ìœ¼ë¡œ ì½ì–´ COCO í˜•ì‹ì˜\n",
    "    ì´ë¯¸ì§€, ì–´ë…¸í…Œì´ì…˜, ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ëª¨ìŒ.\n",
    "\n",
    "    Returns:\n",
    "        images_map: {image_id: image_info}\n",
    "        annotations_map: {image_id: [annotation, ...]}\n",
    "        categories_map: {category_id: category_info}\n",
    "        chart_map: {image_id: [chart_label, ...]}  # ì´ë¯¸ì§€ë³„ ì°¨íŠ¸ ë ˆì´ë¸” ëª©ë¡\n",
    "    \"\"\"\n",
    "    images_map = defaultdict(lambda: None)\n",
    "    annotations_map = defaultdict(list)\n",
    "    categories_map = dict()\n",
    "    chart_map = defaultdict(list)\n",
    "\n",
    "    for root, _, files in os.walk(json_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                with open(os.path.join(root, file), 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                img_info = data['images'][0]\n",
    "                img_id = img_info['id']\n",
    "                images_map[img_id] = img_info\n",
    "\n",
    "                for ann in data['annotations']:\n",
    "                    annotations_map[img_id].append(ann)\n",
    "\n",
    "                for cat in data['categories']:\n",
    "                    categories_map[cat['id']] = cat\n",
    "\n",
    "                chart = img_info.get(\"chart\", \"\")\n",
    "                chart_map[img_id].append(chart)\n",
    "\n",
    "    return images_map, annotations_map, categories_map, chart_map\n",
    "\n",
    "def visualize_overlapping_bboxes_with_all_labels(images_map, annotations_map, categories_map, chart_map, source_img_dir, iou_threshold=0.1):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ë³„ ë°”ìš´ë”© ë°•ìŠ¤ ì¤‘ë³µ(ê²¹ì¹¨) ì—¬ë¶€ë¥¼ IoU ê¸°ì¤€ìœ¼ë¡œ ê²€ì‚¬í•˜ê³ ,\n",
    "    ì¤‘ë³µëœ ë°”ìš´ë”© ë°•ìŠ¤ë“¤ì„ ì„œë¡œ ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ ì‹œê°í™”í•˜ì—¬ ì¶œë ¥.\n",
    "\n",
    "    Args:\n",
    "        images_map: {image_id: image_info}\n",
    "        annotations_map: {image_id: [annotation, ...]}\n",
    "        categories_map: {category_id: category_info}\n",
    "        chart_map: {image_id: [chart_label, ...]}\n",
    "        source_img_dir (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ\n",
    "        iou_threshold (float): IoU ì„ê³„ê°’ (ì´ìƒì¸ ê²½ìš° ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼)\n",
    "\n",
    "    Returns:\n",
    "        None. ê° ì¤‘ë³µ ì´ë¯¸ì§€ì— ëŒ€í•´ ì‹œê°í™” í”Œë¡¯ ì¶œë ¥.\n",
    "    \"\"\"\n",
    "    base_colors = ['red', 'green', 'blue', 'orange', 'purple', 'cyan', 'magenta', 'brown']\n",
    "\n",
    "    for img_id in images_map:\n",
    "        anns = annotations_map[img_id]\n",
    "        if len(anns) <= 1:\n",
    "            continue\n",
    "\n",
    "        boxes = []\n",
    "        for ann in anns:\n",
    "            x, y, w, h = ann['bbox']\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "\n",
    "        overlapping_pairs = []\n",
    "        for i in range(len(boxes)):\n",
    "            for j in range(i + 1, len(boxes)):\n",
    "                iou = compute_iou(boxes[i], boxes[j])\n",
    "                if iou >= iou_threshold:\n",
    "                    overlapping_pairs.append((i, j))\n",
    "\n",
    "        if not overlapping_pairs:\n",
    "            continue\n",
    "\n",
    "        overlapping_indices = set()\n",
    "        for i, j in overlapping_pairs:\n",
    "            overlapping_indices.add(i)\n",
    "            overlapping_indices.add(j)\n",
    "\n",
    "        img_file = images_map[img_id]['file_name']\n",
    "        img_path = os.path.join(source_img_dir, img_file)\n",
    "\n",
    "        # âœ… íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨ ì‹œ ê²½ê³  ì¶œë ¥ í›„ ê±´ë„ˆë›°ê¸°\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âš  ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {img_file}, ê±´ë„ˆëœ€\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Image: {img_file} - Overlapping bbox pairs (IoUâ‰¥{iou_threshold}): {overlapping_pairs}\")\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(img)\n",
    "        ax = plt.gca()\n",
    "\n",
    "        for i, ann in enumerate(anns):\n",
    "            x, y, w, h = ann['bbox']\n",
    "            color = base_colors[i % len(base_colors)] if i in overlapping_indices else 'black'\n",
    "\n",
    "            rect = plt.Rectangle((x, y), w, h, linewidth=2, edgecolor=color, facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "            chart_label = chart_map[img_id][i] if i < len(chart_map[img_id]) else \"N/A\"\n",
    "            category_id = ann.get(\"category_id\")\n",
    "            category_name = categories_map.get(category_id, {}).get(\"name\", \"unknown\")\n",
    "\n",
    "            y_text = max(y - 10, 5)\n",
    "            ax.text(x, y_text, f\"[{i}] {category_name} - {chart_label}\",\n",
    "                    color=color, fontsize=12,\n",
    "                    bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
    "\n",
    "        plt.axis('off')\n",
    "\n",
    "        label_lines = []\n",
    "        for i, ann in enumerate(anns):\n",
    "            chart_label = chart_map[img_id][i] if i < len(chart_map[img_id]) else \"N/A\"\n",
    "            category_id = ann.get(\"category_id\")\n",
    "            category_name = categories_map.get(category_id, {}).get(\"name\", \"unknown\")\n",
    "            label_lines.append(f\"[{i}] {category_name} - {chart_label}\")\n",
    "\n",
    "        y_start = 0.95\n",
    "        for idx, line in enumerate(label_lines):\n",
    "            plt.figtext(0.01, y_start - idx * 0.03, line, fontsize=10,\n",
    "                        ha='left', va='top', color='black',\n",
    "                        bbox=dict(facecolor='white', alpha=0.5, edgecolor='gray'))\n",
    "\n",
    "        plt.title(f\"{img_file} - Overlapping BBoxes (IoUâ‰¥{iou_threshold})\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "QJgjTRnSsg-x"
   },
   "outputs": [],
   "source": [
    "# @title ì¦ê°• ì´ë¯¸ì§€ ë°”ìš´ë”©ë°•ìŠ¤ ì˜¤ë¥˜ í™•ì¸\n",
    "def load_yolo_labels(txt_path, img_w, img_h):\n",
    "    \"\"\"\n",
    "    YOLO ë¼ë²¨ íŒŒì¼ì„ ì½ì–´ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¥¼ (cls_id, x1, y1, x2, y2) í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜.\n",
    "\n",
    "    Args:\n",
    "        txt_path (str): YOLO í˜•ì‹ ë¼ë²¨(txt) íŒŒì¼ ê²½ë¡œ\n",
    "        img_w (int): ì´ë¯¸ì§€ ë„ˆë¹„\n",
    "        img_h (int): ì´ë¯¸ì§€ ë†’ì´\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: [(cls_id, x1, y1, x2, y2), ...]\n",
    "    \"\"\"\n",
    "    boxes = []\n",
    "    with open(txt_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            cls_id, cx, cy, w, h = map(float, parts)\n",
    "            x1 = (cx - w / 2) * img_w\n",
    "            y1 = (cy - h / 2) * img_h\n",
    "            x2 = (cx + w / 2) * img_w\n",
    "            y2 = (cy + h / 2) * img_h\n",
    "            boxes.append((int(cls_id), x1, y1, x2, y2))\n",
    "    return boxes\n",
    "\n",
    "def is_out_of_bounds(box, img_w, img_h):\n",
    "    \"\"\"\n",
    "    ë°”ìš´ë”© ë°•ìŠ¤ê°€ ì´ë¯¸ì§€ ê²½ê³„ ë°–ìœ¼ë¡œ ë²—ì–´ë‚¬ëŠ”ì§€ ì—¬ë¶€ë¥¼ ê²€ì‚¬.\n",
    "\n",
    "    Args:\n",
    "        box (tuple): (cls_id, x1, y1, x2, y2)\n",
    "        img_w (int): ì´ë¯¸ì§€ ë„ˆë¹„\n",
    "        img_h (int): ì´ë¯¸ì§€ ë†’ì´\n",
    "\n",
    "    Returns:\n",
    "        bool: ë°•ìŠ¤ê°€ ì´ë¯¸ì§€ ê²½ê³„ ë°–ì— ìˆìœ¼ë©´ True, ì•„ë‹ˆë©´ False\n",
    "    \"\"\"\n",
    "    _, x1, y1, x2, y2 = box\n",
    "    return x1 < 0 or y1 < 0 or x2 > img_w or y2 > img_h\n",
    "\n",
    "def compute_iou_yolo(box1, box2):\n",
    "    \"\"\"\n",
    "    ë‘ ë°”ìš´ë”© ë°•ìŠ¤ ê°„ IoU(Intersection over Union) ê³„ì‚°.\n",
    "\n",
    "    Args:\n",
    "        box1, box2 (tuple): ê°ê° (cls_id, x1, y1, x2, y2) í˜•ì‹ì˜ ë°•ìŠ¤ ì¢Œí‘œ\n",
    "\n",
    "    Returns:\n",
    "        float: ë‘ ë°•ìŠ¤ì˜ IoU ê°’ (0~1)\n",
    "    \"\"\"\n",
    "    _, x1, y1, x2, y2 = box1\n",
    "    _, x3, y3, x4, y4 = box2\n",
    "    xi1, yi1 = max(x1, x3), max(y1, y3)\n",
    "    xi2, yi2 = min(x2, x4), min(y2, y4)\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x4 - x3) * (y4 - y3)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    return inter_area / union_area if union_area != 0 else 0\n",
    "\n",
    "def show_image_with_boxes(img, boxes, out_classes, overlap_classes, fname):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ì— ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦¬ê³ , ê²½ê³„ ë°– ë°•ìŠ¤ëŠ” ë¹¨ê°„ìƒ‰, ê²¹ì¹˜ëŠ” ë°•ìŠ¤ëŠ” ì£¼í™©ìƒ‰, ì •ìƒ ë°•ìŠ¤ëŠ” íŒŒë€ìƒ‰ìœ¼ë¡œ í‘œì‹œí•˜ì—¬ ì‹œê°í™”.\n",
    "\n",
    "    Args:\n",
    "        img (ndarray): RGB ì´ë¯¸ì§€ ë°°ì—´\n",
    "        boxes (list): [(cls_id, x1, y1, x2, y2), ...] ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸\n",
    "        out_classes (set): ì´ë¯¸ì§€ ë°– ë°•ìŠ¤ê°€ ìˆëŠ” í´ë˜ìŠ¤ ID ì§‘í•©\n",
    "        overlap_classes (set): ê²¹ì¹˜ëŠ” ë°•ìŠ¤ê°€ ìˆëŠ” í´ë˜ìŠ¤ ID ì§‘í•©\n",
    "        fname (str): ì´ë¯¸ì§€ íŒŒì¼ëª… (í”Œë¡¯ ì œëª©ì— ì‚¬ìš©)\n",
    "    \"\"\"\n",
    "    img_h, img_w = img.shape[:2]\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "    ax.imshow(img)\n",
    "\n",
    "    for box in boxes:\n",
    "        cls_id, x1, y1, x2, y2 = box\n",
    "        color = 'blue'\n",
    "        if cls_id in out_classes:\n",
    "            color = 'red'\n",
    "        elif cls_id in overlap_classes:\n",
    "            color = 'orange'\n",
    "\n",
    "        rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1,\n",
    "                                 linewidth=2, edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1, y1 - 4, f'{cls_id}', color=color, fontsize=10)\n",
    "\n",
    "    title = f\"{fname}\"\n",
    "    if out_classes or overlap_classes:\n",
    "        title += \"  [âš ï¸ í™•ì¸ í•„ìš”]\"\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def process_image(image_path, label_path, fname):\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ ì´ë¯¸ì§€ì™€ ë¼ë²¨ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ë°”ìš´ë”© ë°•ìŠ¤ê°€ ì´ë¯¸ì§€ ë°–ì— ìˆëŠ”ì§€,\n",
    "    ì„œë¡œ ê²¹ì¹˜ëŠ” ë°•ìŠ¤ê°€ ìˆëŠ”ì§€ ê²€ì‚¬í•˜ê³ , ì´ìƒì´ ìˆìœ¼ë©´ ì‹œê°í™”í•´ì„œ ì¶œë ¥.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ\n",
    "        label_path (str): YOLO ë¼ë²¨ íŒŒì¼ ê²½ë¡œ\n",
    "        fname (str): ì´ë¯¸ì§€ íŒŒì¼ëª… (ì¶œë ¥ìš©)\n",
    "\n",
    "    Returns:\n",
    "        tuple(bool, bool) or None: (ì´ë¯¸ì§€ ë°– ë°•ìŠ¤ ì—¬ë¶€, ê²¹ì¹˜ëŠ” ë°•ìŠ¤ ì—¬ë¶€)\n",
    "                                   ë°”ìš´ë”© ë°•ìŠ¤ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"[Error] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_h, img_w = img.shape[:2]\n",
    "\n",
    "    boxes = load_yolo_labels(label_path, img_w, img_h)\n",
    "    if not boxes:\n",
    "        return None\n",
    "\n",
    "    out_classes = set()\n",
    "    overlap_classes = set()\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        cls_id = box[0]\n",
    "\n",
    "        if is_out_of_bounds(box, img_w, img_h):\n",
    "            out_classes.add(cls_id)\n",
    "\n",
    "        for j in range(i + 1, len(boxes)):\n",
    "            iou = compute_iou_yolo(box, boxes[j])\n",
    "            if iou > 0:\n",
    "                overlap_classes.add(cls_id)\n",
    "                overlap_classes.add(boxes[j][0])\n",
    "\n",
    "    if out_classes or overlap_classes:\n",
    "        print(f\"ğŸ“‚ {fname}\")\n",
    "        if out_classes:\n",
    "            print(f\"  ğŸ”´ ì´ë¯¸ì§€ ë°– í´ë˜ìŠ¤: {sorted(out_classes)}\")\n",
    "        if overlap_classes:\n",
    "            print(f\"  ğŸŸ  ê²¹ì¹˜ëŠ” í´ë˜ìŠ¤: {sorted(overlap_classes)}\\n\")\n",
    "        show_image_with_boxes(img, boxes, out_classes, overlap_classes, fname)\n",
    "\n",
    "    return len(out_classes) > 0, len(overlap_classes) > 0\n",
    "\n",
    "def process_folder(images_dir, labels_dir):\n",
    "    \"\"\"\n",
    "    ì§€ì •í•œ í´ë” ë‚´ ì´ë¯¸ì§€ì™€ ë¼ë²¨ë“¤ì„ ëª¨ë‘ ê²€ì‚¬í•˜ì—¬,\n",
    "    ì´ë¯¸ì§€ ë°– ë°”ìš´ë”© ë°•ìŠ¤ ë° ê²¹ì¹˜ëŠ” ë°•ìŠ¤ê°€ ìˆëŠ” ì´ë¯¸ì§€ ëª©ë¡ê³¼ í†µê³„ë¥¼ ì¶œë ¥.\n",
    "\n",
    "    Args:\n",
    "        images_dir (str): ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "        labels_dir (str): YOLO ë¼ë²¨(txt) íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    out_count = 0\n",
    "    overlap_count = 0\n",
    "\n",
    "    print(\"ğŸ” ì˜¤ë¥˜ ìˆëŠ” íŒŒì¼ ëª©ë¡:\\n\")\n",
    "\n",
    "    for fname in sorted(os.listdir(images_dir)):\n",
    "        if not fname.endswith('.png'):\n",
    "            continue\n",
    "\n",
    "        name_no_ext = os.path.splitext(fname)[0]\n",
    "        image_path = os.path.join(images_dir, fname)\n",
    "        label_path = os.path.join(labels_dir, name_no_ext + '.txt')\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            continue\n",
    "\n",
    "        result = process_image(image_path, label_path, fname)\n",
    "        if result:\n",
    "            total += 1\n",
    "            out, overlap = result\n",
    "            if out:\n",
    "                out_count += 1\n",
    "            if overlap:\n",
    "                overlap_count += 1\n",
    "\n",
    "    print(\"ğŸ“Š í†µê³„ ìš”ì•½:\")\n",
    "    print(f\"  ì „ì²´ ì˜¤ë¥˜ ì´ë¯¸ì§€ ìˆ˜: {total}\")\n",
    "    print(f\"  ğŸ”´ ì´ë¯¸ì§€ ë°– ë°•ìŠ¤ í¬í•¨ ìˆ˜: {out_count}\")\n",
    "    print(f\"  ğŸŸ  ê²¹ì¹˜ëŠ” ë°•ìŠ¤ í¬í•¨ ìˆ˜: {overlap_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Ok-JRUWRGB-z"
   },
   "outputs": [],
   "source": [
    "# @title ì¦ê°• ì „í›„ ë°ì´í„°ë¶„í¬ ë¹„êµ\n",
    "def plot_class_distribution(before_counts, after_counts):\n",
    "    \"\"\"\n",
    "    í´ë˜ìŠ¤ ë¶„í¬ë¥¼ ì¦ê°• ì „í›„ë¡œ ê²¹ì³ì„œ ë¹„êµí•˜ëŠ” ë§‰ëŒ€ ê·¸ë˜í”„ë¥¼ ê·¸ë¦°ë‹¤.\n",
    "\n",
    "    Args:\n",
    "        before_counts (dict): ì¦ê°• ì „ í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜\n",
    "        after_counts (dict): ì¦ê°• í›„ í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜\n",
    "    \"\"\"\n",
    "    sorted_classes = sorted(before_counts.keys(), key=lambda x: int(x))\n",
    "    before_values = [before_counts.get(cls, 0) for cls in sorted_classes]\n",
    "    after_values = [after_counts.get(cls, 0) for cls in sorted_classes]\n",
    "\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(sorted_classes))\n",
    "\n",
    "    plt.figure(figsize=(17, 6))\n",
    "    plt.bar(index, before_values, bar_width, color='#FF6F61', label='Before Augmentation')\n",
    "    plt.bar(index, after_values, bar_width, color='#6C9ECF', label='After Augmentation', alpha=0.5)\n",
    "\n",
    "    max_value = max(max(before_values), max(after_values))\n",
    "    plt.ylim(0, max_value)\n",
    "    plt.yticks(np.arange(0, max_value + 1, 25))\n",
    "\n",
    "    for y in np.arange(0, max_value + 1, 25):\n",
    "        plt.axhline(y=y, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.ylabel('ì´ë¯¸ì§€ìˆ˜')\n",
    "    plt.title('Class Distribution Before and After Augmentation')\n",
    "    plt.xticks(index, sorted_classes, rotation=90)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "_aWU_t5i3p6i"
   },
   "outputs": [],
   "source": [
    "# @title ì¦ê°• ì´ë¯¸ì§€ í™•ì¸\n",
    "def read_yolo_labels(label_path):\n",
    "    \"\"\"\n",
    "    YOLO txt ë¼ë²¨ì„ ì½ì–´ (cls, xywh center normalized) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜.\n",
    "    \"\"\"\n",
    "    boxes = []\n",
    "    if not os.path.isfile(label_path):\n",
    "        print(f\"Warning: {label_path} does not exist.\")\n",
    "        return boxes\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            cls_id = int(parts[0])\n",
    "            x_c, y_c, w, h = map(float, parts[1:])\n",
    "            boxes.append((cls_id, x_c, y_c, w, h))\n",
    "    return boxes\n",
    "\n",
    "def generate_class_colors(num_classes):\n",
    "    \"\"\"\n",
    "    í´ë˜ìŠ¤ë³„ë¡œ ëœë¤í•œ RGB ìƒ‰ìƒ ë¦¬ìŠ¤íŠ¸ ìƒì„± (ê³ ì • ì‹œë“œ ì‚¬ìš©).\n",
    "    \"\"\"\n",
    "    random.seed(42)\n",
    "    colors = []\n",
    "    for _ in range(num_classes):\n",
    "        colors.append((random.randint(0,255), random.randint(0,255), random.randint(0,255)))\n",
    "    return colors\n",
    "\n",
    "def draw_bboxes(img, boxes, class_colors, thickness=4):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ì— ê° í´ë˜ìŠ¤ë³„ ìƒ‰ìƒìœ¼ë¡œ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°.\n",
    "    boxes: (cls_id, x_c, y_c, w, h) í˜•ì‹ (YOLO normalized)\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    for cls_id, x_c, y_c, bw, bh in boxes:\n",
    "        x1 = int((x_c - bw/2) * w)\n",
    "        y1 = int((y_c - bh/2) * h)\n",
    "        x2 = int((x_c + bw/2) * w)\n",
    "        y2 = int((y_c + bh/2) * h)\n",
    "        color = class_colors[cls_id]\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), color, thickness)\n",
    "\n",
    "def count_classes_in_boxes(boxes):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸ì—ì„œ í´ë˜ìŠ¤ë³„ ê°œìˆ˜ ì„¸ê¸°.\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    for cls_id, _, _, _, _ in boxes:\n",
    "        if cls_id not in class_counts:\n",
    "            class_counts[cls_id] = 0\n",
    "        class_counts[cls_id] += 1\n",
    "    return class_counts\n",
    "\n",
    "def show_augmented_images_by_class(\n",
    "    images_dir,\n",
    "    labels_dir,\n",
    "    max_aug_images=5,\n",
    "    num_classes=74\n",
    "):\n",
    "    \"\"\"\n",
    "    í´ë˜ìŠ¤ë³„ë¡œ ì¦ê°•ëœ ì´ë¯¸ì§€ë“¤ì„ ë¬´ì‘ìœ„ë¡œ ìµœëŒ€ max_aug_imagesê°œì”© ì‹œê°í™”í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        images_dir (str): ì¦ê°• ì´ë¯¸ì§€ë“¤ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "        labels_dir (str): ì¦ê°• ì´ë¯¸ì§€ì— ëŒ€ì‘í•˜ëŠ” YOLO ë¼ë²¨(txt) íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "        max_aug_images (int): ê° í´ë˜ìŠ¤ë³„ë¡œ ìµœëŒ€ ëª‡ ì¥ì˜ ì¦ê°• ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì¤„ì§€ ì§€ì • (ê¸°ë³¸ 5)\n",
    "        num_classes (int): ì´ í´ë˜ìŠ¤ ê°œìˆ˜ (ë¼ë²¨ ìƒ‰ìƒ ë° í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ë²”ìœ„ ì§€ì •ìš©)\n",
    "    \"\"\"\n",
    "    valid_exts = ('.png')\n",
    "    all_files = [f for f in os.listdir(images_dir) if f.lower().endswith(valid_exts)]\n",
    "\n",
    "    # ì›ë³¸ ì´ë¯¸ì§€ì™€ ì¦ê°• ì´ë¯¸ì§€ë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•´, '_aug' ë˜ëŠ” '_crop'ì´ í¬í•¨ëœ íŒŒì¼ë§Œ ì„ íƒ\n",
    "    aug_files = [f for f in all_files if \"_aug\" in f or \"_crop\" in f]\n",
    "    print(f\"Found {len(aug_files)} augmented files: {aug_files}\")\n",
    "\n",
    "    # í´ë˜ìŠ¤ë³„ ì¦ê°•ëœ ì´ë¯¸ì§€ë¥¼ êµ¬ë¶„\n",
    "    class_to_aug_files = {i: [] for i in range(num_classes)}  # í´ë˜ìŠ¤ë³„ë¡œ ì¦ê°• ì´ë¯¸ì§€ ì €ì¥\n",
    "\n",
    "    for aug_file in aug_files:\n",
    "        aug_label_path = os.path.join(labels_dir, os.path.splitext(aug_file)[0] + '.txt')\n",
    "        if not os.path.isfile(aug_label_path):\n",
    "            continue\n",
    "\n",
    "        # ë¼ë²¨ íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ ì¶”ì¶œ\n",
    "        aug_boxes = read_yolo_labels(aug_label_path)\n",
    "        for cls_id, _, _, _, _ in aug_boxes:\n",
    "            if cls_id < num_classes:\n",
    "                class_to_aug_files[cls_id].append(aug_file)\n",
    "                break  # ì²« ë²ˆì§¸ í´ë˜ìŠ¤ë§Œ ê°€ì ¸ì˜´\n",
    "\n",
    "    class_colors = generate_class_colors(num_classes)\n",
    "\n",
    "    # ê° í´ë˜ìŠ¤ë³„ë¡œ ì¦ê°• ì´ë¯¸ì§€ ëœë¤ ì¶œë ¥\n",
    "    for cls_id, aug_files in class_to_aug_files.items():\n",
    "        if len(aug_files) > 0:\n",
    "            # ë¬´ì‘ìœ„ë¡œ 5ê°œì˜ ì¦ê°• ì´ë¯¸ì§€ ì„ íƒ\n",
    "            selected_aug_files = random.sample(aug_files, min(max_aug_images, len(aug_files)))\n",
    "\n",
    "            aug_imgs = []\n",
    "            for aug_file in selected_aug_files:\n",
    "                aug_img_path = os.path.join(images_dir, aug_file)\n",
    "                aug_label_path = os.path.join(labels_dir, os.path.splitext(aug_file)[0] + '.txt')\n",
    "                aug_img = cv2.imread(aug_img_path)\n",
    "                aug_img = cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB)\n",
    "                aug_boxes = read_yolo_labels(aug_label_path)\n",
    "                draw_bboxes(aug_img, aug_boxes, class_colors)\n",
    "\n",
    "                aug_imgs.append(aug_img)\n",
    "\n",
    "            total_imgs = len(aug_imgs)\n",
    "            plt.figure(figsize=(5 * total_imgs, 6))  # ë” ë„“ê³  ì—¬ìœ  ìˆëŠ” ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
    "            plt.suptitle(f\"Class {cls_id} - {len(aug_imgs)} Augmented Images\", fontsize=16)\n",
    "\n",
    "            # ì¦ê°• ì´ë¯¸ì§€ë“¤ (ê°€ë¡œë¡œ ì •ë ¬í•˜ê³ , ìœ„ìª½ì— ë§ì¶”ê¸°)\n",
    "            for idx, aug_img in enumerate(aug_imgs, start=1):\n",
    "                plt.subplot(1, total_imgs, idx)  # 1í–‰ ì—¬ëŸ¬ ì—´ë¡œ ë°°ì¹˜\n",
    "                plt.imshow(aug_img)\n",
    "                plt.title(f\"Augmented {idx}\")\n",
    "                plt.axis('off')\n",
    "\n",
    "            # ì—¬ë°±ì„ ì¡°ì •í•˜ì—¬ ì´ë¯¸ì§€ ê°„ ê°„ê²©ì„ ë” ë„“íˆê³  ìƒë‹¨ì— ë§ì¶”ê¸°\n",
    "            plt.subplots_adjust(top=0.85, bottom=0.05, left=0.05, right=0.95, hspace=0.1, wspace=0.2)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKys0WbO0xVn"
   },
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "CC8H6wLDqGul"
   },
   "outputs": [],
   "source": [
    "# 0) ì¤‘ë³µ/ê²¹ì¹˜ëŠ” ë°”ìš´ë”©ë°•ìŠ¤ í™•ì¸\n",
    "images_map, annotations_map, categories_map, chart_map = merge_all_jsons_recursive(source_label_dir)\n",
    "visualize_overlapping_bboxes_with_all_labels(images_map, annotations_map, categories_map, chart_map, source_img_dir, iou_threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "kwUyEeObz2f-"
   },
   "outputs": [],
   "source": [
    "# 1) ì–´ë…¸í…Œì´ì…˜ ë³‘í•©\n",
    "merge_coco_jsons(source_label_dir, merged_json_path)\n",
    "\n",
    "# 2) ì¹´í…Œê³ ë¦¬ ë§¤í•‘\n",
    "master_cat_id_to_idx = get_master_categories([merged_json_path])[0]\n",
    "\n",
    "# 3) ì™„ì „ ë¼ë²¨ ë°ì´í„° í•„í„°ë§\n",
    "clean_invalid_yolo_files_from_dir(\n",
    "    merged_json_path=merged_json_path,\n",
    "    image_dir=source_img_dir,\n",
    "    label_dir=source_label_dir\n",
    ")\n",
    "\n",
    "# 4) í•„í„°ë§ëœ ë°ì´í„° ì–´ë…¸í…Œì´ì…˜ ë³‘í•©\n",
    "merge_coco_jsons(source_label_dir, merged_filtered_json_path)\n",
    "\n",
    "# 4) ì´ë¯¸ì§€ ë³µì‚¬\n",
    "image_files = get_image_files_from_coco_json(merged_filtered_json_path)\n",
    "copy_images(image_files, source_img_dir, yolo_image_dir)\n",
    "\n",
    "# 3) YOLO ë¼ë²¨ ë³€í™˜\n",
    "convert_coco_to_yolo(\n",
    "    annotation_file=merged_filtered_json_path,\n",
    "    source_img_dir=yolo_image_dir,\n",
    "    target_yolo_dir=yolo_label_dir,\n",
    "    master_cat_id_to_idx=master_cat_id_to_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "vjXW68kVGfrf"
   },
   "outputs": [],
   "source": [
    "# 4) train/val ë¶„í• \n",
    "split_train_val(\n",
    "    image_dir=yolo_image_dir,\n",
    "    label_dir=yolo_label_dir,\n",
    "    train_img_dir=os.path.join(yolo_image_dir, \"train_images\"),\n",
    "    val_img_dir=os.path.join(yolo_image_dir, \"val_images\"),\n",
    "    train_label_dir=os.path.join(yolo_label_dir, \"train_images\"),\n",
    "    val_label_dir=os.path.join(yolo_label_dir, \"val_images\"),\n",
    "    val_ratio=0.15,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# í•™ìŠµ/ê²€ì¦ ë°ì´í„° ì´ë¯¸ì§€/ë¼ë²¨ìˆ˜ í™•ì¸\n",
    "print(\"=== Train Dataset Check ===\")\n",
    "check_images_labels(yolo_train_img_dir, yolo_train_label_dir)\n",
    "\n",
    "print(\"\\n=== Validation Dataset Check ===\")\n",
    "check_images_labels(yolo_val_img_dir, yolo_val_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "9XE-8PT1wyGK"
   },
   "outputs": [],
   "source": [
    "# 5) train ì´ë¯¸ì§€ ì¦ê°•. í´ë˜ìŠ¤ë³„ ìµœëŒ€ 75ê°œ\n",
    "before_counts = count_classes_in_yolo_txt(yolo_train_label_dir)\n",
    "cat_id_to_index, cat_id_to_name = get_master_categories([merged_json_path])\n",
    "copy_few_shot_images(\n",
    "    yolo_img_dir=yolo_train_img_dir,\n",
    "    yolo_label_dir=yolo_train_label_dir,\n",
    "    cat_id_to_name=cat_id_to_name,\n",
    "    max_classes_threshold=76,\n",
    "    top_n=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "y_ZKcDv4_Jiu"
   },
   "outputs": [],
   "source": [
    "# 6) 75ê°œ ì´ìƒ ì¡´ì¬í•˜ëŠ” ì´ë¯¸ì§€/ë¼ë²¨ ì‚­ì œ\n",
    "fine_tune_delete_by_class_popularity_relaxed(\n",
    "    yolo_train_img_dir,\n",
    "    yolo_train_label_dir,\n",
    "    76,\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-sZrEQC2P_1"
   },
   "outputs": [],
   "source": [
    "# 7) ì¦ê°•(ì‚­ì œ) ì „í›„ ë°ì´í„° ë¶„í¬ í™•ì¸\n",
    "after_counts = count_classes_in_yolo_txt(yolo_train_label_dir)\n",
    "\n",
    "plot_class_distribution(before_counts, after_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "IcmiN27Vslia"
   },
   "outputs": [],
   "source": [
    "# 8) ì¦ê°• ë°ì´í„° ê²€ì¦\n",
    "process_folder(\n",
    "    images_dir=yolo_train_img_dir,\n",
    "    labels_dir=yolo_train_label_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VyqbmzYCDGJc"
   },
   "outputs": [],
   "source": [
    "# 9) ì¦ê°•ëœ ì´ë¯¸ì§€ í™•ì¸\n",
    "show_augmented_images_by_class(yolo_train_img_dir, yolo_train_label_dir, max_aug_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Q6IY0Kv8occ"
   },
   "outputs": [],
   "source": [
    "# 10) data.yaml íŒŒì¼ ìƒì„±\n",
    "cat_id_to_index, cat_id_to_name = get_master_categories([merged_json_path])\n",
    "\n",
    "# YOLOìš© í´ë˜ìŠ¤ ì¸ë±ìŠ¤ â†’ í´ë˜ìŠ¤ëª…\n",
    "names_dict = {\n",
    "    idx: cat_id_to_name[cat_id]\n",
    "    for cat_id, idx in cat_id_to_index.items()\n",
    "}\n",
    "\n",
    "yaml_path = \"/kaggle/working/data/data.yaml\"\n",
    "yaml_dir = os.path.dirname(yaml_path)\n",
    "create_yolo_yaml(root_dir, merged_json_path, yaml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pof8B6Fv806C"
   },
   "outputs": [],
   "source": [
    "# 11) ëª¨ë¸í•™ìŠµ\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=150,\n",
    "    imgsz=640,\n",
    "    patience=20,\n",
    "    batch=16,\n",
    "    device=0,\n",
    "    lr0=0.01,\n",
    "    lrf=0.01,\n",
    "    mosaic=0.5,\n",
    "    mixup=0.2,\n",
    "    close_mosaic=10,\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    flipud=0.1,\n",
    "    fliplr=0.1,\n",
    "    augment=True,\n",
    "    project=\"/kaggle/working/data/results\",\n",
    "    name=\"yolo8l_custom_train_cp_mix\",\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "SPBkhv9S22Z5",
    "zNfvnxf6z-kt"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7923658,
     "sourceId": 12549767,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
